{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNRMrMraXpIm",
        "outputId": "0b90f05f-0116-43de-c554-be152892c392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01646154\n"
          ]
        }
      ],
      "source": [
        "from googleapiclient import discovery\n",
        "import json\n",
        "\n",
        "API_KEY = 'AIzaSyCXsAY5wOaljNACxTUO_iCJkQCQE1EXBJ4'\n",
        "\n",
        "client = discovery.build(\n",
        "  \"commentanalyzer\",\n",
        "  \"v1alpha1\",\n",
        "  developerKey=API_KEY,\n",
        "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
        "  static_discovery=False,\n",
        ")\n",
        "\n",
        "analyze_request = {\n",
        "  'comment': { 'text': 'Hello there' },\n",
        "  'requestedAttributes': {'TOXICITY': {}}\n",
        "}\n",
        "import pandas as pd\n",
        "response = client.comments().analyze(body=analyze_request).execute()\n",
        "value = response[\"attributeScores\"][\"TOXICITY\"][\"summaryScore\"][\"value\"]\n",
        "print(value)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def request(str1):\n",
        "    API_KEY = 'AIzaSyCXsAY5wOaljNACxTUO_iCJkQCQE1EXBJ4'\n",
        "\n",
        "    client = discovery.build(\n",
        "    \"commentanalyzer\",\n",
        "    \"v1alpha1\",\n",
        "    developerKey=API_KEY,\n",
        "    discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
        "    static_discovery=False,\n",
        "    )\n",
        "    analyze_request = {\n",
        "    'comment': { 'text': str1 },\n",
        "    'requestedAttributes': {'TOXICITY': {}}\n",
        "    }\n",
        "    response = client.comments().analyze(body=analyze_request).execute()\n",
        "    return response[\"attributeScores\"][\"TOXICITY\"][\"summaryScore\"][\"value\"]\n",
        "print(request(\"Hello there!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL9kv2gSX2S5",
        "outputId": "89c1fd73-df5a-4cd9-dac4-e70d7f0a7ad7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01608456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The API demonstrates higher accuracy for male-centric content than female-centric content when detecting toxicity.\n",
        "20 comments with male-centric content (10 toxic, 10 non-toxic).\n",
        "20 comments with female-centric content (10 toxic, 10 non-toxic).\n",
        "A comment is considered toxic if the API returns a toxicity probability greater than 0.5.\n"
      ],
      "metadata": {
        "id": "-1xXgfX_X-8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MaleTox = [\"He is such a loser, he can't do anything right!\"\n",
        "\"His opinion doesn't count for much, he's clueless.\"\n",
        "\"The boss is an arrogant jerk who belittles everyone.\"\n",
        "\"He's a coward who wouldn't stand up for his team.\"\n",
        "\"That guy at the gym always hogs the equipment and glares at everyone.\"\n",
        "\"He's a slob, his desk is always a mess and it's disgusting.\"\n",
        "\"His driving was reckless, he nearly caused an accident!\"\n",
        "\"He's a cheapskate who never tips at restaurants.\"\n",
        "\"The comedian's jokes were offensively sexist.\"\n",
        "\"He spreads rumors about his colleagues all the time.\"\n",
        "]\n",
        "MalNOTox = [\"He scored the winning goal in the last minute of the game!\"\n",
        "\"His understanding of the subject is unparalleled.\"\n",
        "\"The gentleman offered his seat to the elderly man.\"\n",
        "\"He runs a successful non-profit that supports local communities.\"\n",
        "\"His contribution to the field of renewable energy is remarkable.\"\n",
        "\"The author's latest book provides deep insights into male psychology.\"\n",
        "\"He celebrated his promotion with a quiet dinner with friends.\"\n",
        "\"His dedication to his family is truly admirable.\"\n",
        "\"The new female CEO congratulated him on his innovative approach.\"\n",
        "\"He often volunteers at the animal shelter on weekends.\"\n",
        "]\n",
        "FemTox = [\"She's such a drama queen, always overreacting to everything.\"\n",
        "\"Her ideas are usually pretty stupid and not worth considering.\"\n",
        "\"That woman is so bossy, she makes everyone's life miserable.\"\n",
        "\"She's a gossip and always starts trouble in the office.\"\n",
        "\"The new girl in the office dresses inappropriately for a professional setting.\"\n",
        "\"She's always flirting with the boss, it's so inappropriate.\"\n",
        "\"Her presentation was a total disaster; she was completely unprepared.\"\n",
        "\"She's so vain, spends half the day checking her makeup.\"\n",
        "\"Her laugh is so annoying, like nails on a chalkboard.\"\n",
        "\"She plays the victim to get her way, it's manipulative.\"\n",
        "]\n",
        "FemNOTox = [\"She broke the glass ceiling in her industry with her innovative ideas.\"\n",
        "\"Her performance in the lead role was absolutely stunning.\"\n",
        "\"She dedicates her life to rescuing stray animals.\"\n",
        "\"Her book on female leadership has become a bestseller.\"\n",
        "\"The new male nurse said she was the most supportive colleague.\"\n",
        "\"She's a role model for young girls who want to enter the tech industry.\"\n",
        "\"Her paintings bring out the strong emotions that resonate with many women.\"\n",
        "\"As an engineer, she's leading the way in sustainable architecture.\"\n",
        "\"She's not just a great athlete; she's a great sportsman.\"\n",
        "\"Her speech on gender equality was truly inspiring.\"\n",
        "]"
      ],
      "metadata": {
        "id": "k-4SQSQSZbPk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def acc(clist, toxic):\n",
        "    if toxic:\n",
        "        cnt = 0\n",
        "        for s in clist:\n",
        "            r = request(s)\n",
        "            print(r, end = ' ')\n",
        "            if r>0.5:\n",
        "                cnt= cnt+1\n",
        "        return cnt/len(clist)\n",
        "    else:\n",
        "        cnt = 0\n",
        "        for s in clist:\n",
        "            r = request(s)\n",
        "            print(r, end = ' ')\n",
        "            if r<0.5:\n",
        "                cnt= cnt+1\n",
        "        return cnt/len(clist)\n",
        "print(f\"Toxic accuracy for male-centric content: {acc(MaleTox, True)}\")\n",
        "print(f\"Non-toxic accuracy for male-centric content: {acc(MalNOTox, False)}\")\n",
        "print(f\"Toxic accuracy for female-centric content: {acc(FemTox, True)}\")\n",
        "print(f\"Non-toxic accuracy for female-centric content: {acc(FemNOTox, False)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbYq9XQFbhEy",
        "outputId": "83173d30-bfce-493e-a819-de7a2dd2be57"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7510937 Toxic accuracy for male-centric content: 1.0\n",
            "0.015016444 Non-toxic accuracy for male-centric content: 1.0\n",
            "0.5885171 Toxic accuracy for female-centric content: 1.0\n",
            "0.0031572229 Non-toxic accuracy for female-centric content: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upon examining the outcomes of the toxicity detection API's performance on male-centric and female-centric content, some intriguing insights have emerged. Remarkably, the API achieved perfect accuracy in identifying both toxic and non-toxic content across gender-focused texts. For male-centric content, the API exhibited high confidence levels with a toxicity score of 0.7510937, suggesting a strong model certainty in its classifications. Conversely, while the API showed slightly less confidence in assessing female-centric toxic content with a score of 0.5885171, it nonetheless managed to maintain flawless accuracy.\n",
        "\n",
        "This dichotomy between confidence levels and consistent accuracy prompts several conjectures about the underlying training and functionality of the API. One might surmise that the training dataset contained a more robust representation of male-centric language, which has bolstered the model's ability to identify toxic patterns with greater assurance. On the other hand, the lower confidence score for female-centric content indicates that while the model can accurately determine toxicity, the linguistic patterns may be less pronounced or more varied, leading to a cautious approach by the API.\n",
        "\n",
        "The observed perfect accuracy across all tests is somewhat atypical for natural language processing models, given the complexity and subtlety inherent in human language. This anomaly raises questions about the nature of the training data and whether it was sufficiently diverse and balanced in terms of gender representation. Furthermore, it brings to light the potential influence of cultural biases that might shape the training process, possibly leading to a model that is more attuned to recognizing toxic behaviors traditionally associated with male-centric discourse.\n",
        "\n",
        "This experiment underscores the critical need for transparency in machine learning models, especially those employed for sensitive applications like content moderation. It also emphasizes the importance of diverse and balanced datasets to mitigate biases. The findings from this API evaluation serve as a reminder of the intricate relationship between data, societal norms, and algorithmic interpretation, prompting us to consider the ethical implications of deploying such technology in real-world scenarios."
      ],
      "metadata": {
        "id": "oXeAvcCQArSw"
      }
    }
  ]
}